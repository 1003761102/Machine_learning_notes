{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script type=\"text/javascript\" src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default\"></script>\n",
    "# 3 决策树（decision tree）\n",
    "   决策树是一种基本的分类和回归方法，决策树呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。决策树学习主要包括3个步骤：特征选择、决策树的生成和决策树的修剪。下图是一个决策树的示意图，图中圆和方框分别表示内部节点和叶节点。\n",
    "<div align=\"center\">\n",
    "<img width='50%' algin='middle' src='Image/1.jpg'>\n",
    "</div>\n",
    "## 3.1 决策树学习\n",
    "   决策树学习，假设给定训练数据集\n",
    "$$D={(x_1,y_1), (x_2, y_2),...,(x_n, y_n)}$$\n",
    "其中，$x_i=(x_i^{(1)},x_i^{(2)},...,x_i^{(n)})^T为输入实例，n为特征个数，$y_i\\in {1,2,...,K}$为类标记，学习的目的是根据给定训练数据集构建一个决策树模型，使它能够对实例进行正确的分类。\n",
    "## 3.2 特征选择\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    dataset = [['青绿','蜷缩', '浊响', '清晰', '凹陷', '硬滑', '好'],\n",
    "                       ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '好'],\n",
    "                       ['乌黑',' 蜷缩',' 浊响',' 清晰',' 凹陷', '硬滑', '好'],\n",
    "                       ['青绿',' 蜷缩',' 沉闷',' 清晰',' 凹陷', '硬滑', '好'],\n",
    "                       ['浅白',' 蜷缩',' 浊响',' 清晰',' 凹陷', '硬滑', '好'],\n",
    "                       ['青绿',' 稍蜷',' 浊响',' 清晰',' 稍凹', '软粘', '好'],\n",
    "                       ['乌黑',' 稍蜷',' 浊响',' 稍糊',' 稍凹', '软粘', '好'], \n",
    "                       ['乌黑',' 稍蜷',' 浊响',' 清晰',' 稍凹', '硬滑', '好'],\n",
    "                       ['乌黑',' 稍蜷',' 沉闷',' 稍糊',' 稍凹', '硬滑', '坏'],\n",
    "                       ['青绿',' 硬挺',' 清脆',' 清晰',' 平坦', '软粘', '坏'],\n",
    "                       ['浅白',' 硬挺',' 清脆',' 模糊',' 平坦', '硬滑', '坏'], \n",
    "                       ['浅白',' 蜷缩',' 浊响',' 模糊',' 平坦', '软粘', '坏'],\n",
    "                       ['青绿',' 稍蜷',' 浊响',' 稍糊',' 凹陷', '硬滑', '坏'],\n",
    "                       ['浅白',' 稍蜷',' 沉闷',' 稍糊',' 凹陷', '硬滑', '坏'],\n",
    "                       ['乌黑',' 稍蜷',' 浊响',' 清晰',' 稍凹', '软粘', '坏'],\n",
    "                       ['浅白',' 蜷缩',' 浊响',' 模糊',' 平坦', '硬滑', '坏'],\n",
    "                       ['青绿',' 蜷缩',' 沉闷',' 稍糊',' 稍凹', '硬滑', '坏']\n",
    "                      ]\n",
    "  \n",
    "    labels = ['色泽', '根底', '敲声', '纹理', '脐部', '触感', '好瓜']\n",
    "    return dataset, labels\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '好'],\n",
       " ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '好'],\n",
       " ['乌黑', ' 蜷缩', ' 浊响', ' 清晰', ' 凹陷', '硬滑', '好'],\n",
       " ['青绿', ' 蜷缩', ' 沉闷', ' 清晰', ' 凹陷', '硬滑', '好'],\n",
       " ['浅白', ' 蜷缩', ' 浊响', ' 清晰', ' 凹陷', '硬滑', '好'],\n",
       " ['青绿', ' 稍蜷', ' 浊响', ' 清晰', ' 稍凹', '软粘', '好'],\n",
       " ['乌黑', ' 稍蜷', ' 浊响', ' 稍糊', ' 稍凹', '软粘', '好'],\n",
       " ['乌黑', ' 稍蜷', ' 浊响', ' 清晰', ' 稍凹', '硬滑', '好'],\n",
       " ['乌黑', ' 稍蜷', ' 沉闷', ' 稍糊', ' 稍凹', '硬滑', '坏'],\n",
       " ['青绿', ' 硬挺', ' 清脆', ' 清晰', ' 平坦', '软粘', '坏'],\n",
       " ['浅白', ' 硬挺', ' 清脆', ' 模糊', ' 平坦', '硬滑', '坏'],\n",
       " ['浅白', ' 蜷缩', ' 浊响', ' 模糊', ' 平坦', '软粘', '坏'],\n",
       " ['青绿', ' 稍蜷', ' 浊响', ' 稍糊', ' 凹陷', '硬滑', '坏'],\n",
       " ['浅白', ' 稍蜷', ' 沉闷', ' 稍糊', ' 凹陷', '硬滑', '坏'],\n",
       " ['乌黑', ' 稍蜷', ' 浊响', ' 清晰', ' 稍凹', '软粘', '坏'],\n",
       " ['浅白', ' 蜷缩', ' 浊响', ' 模糊', ' 平坦', '硬滑', '坏'],\n",
       " ['青绿', ' 蜷缩', ' 沉闷', ' 稍糊', ' 稍凹', '硬滑', '坏']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, labels = create_data()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算熵\n",
    "def ent_calc(dataset):\n",
    "    length = len(dataset)\n",
    "    label_count = {}\n",
    "    for i in range(length):\n",
    "        label = dataset[i][-1]\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += 1\n",
    "    ent = -sum([pk/length*np.log2(pk/length) for pk in label_count.values()])\n",
    "    return ent\n",
    "\n",
    "# 计算经验熵\n",
    "def ent_resid(dataset, axis=0):\n",
    "    length = len(dataset)\n",
    "    feature_set =  {}\n",
    "    for i in range(length):\n",
    "        f = dataset[i][axis]\n",
    "        if f not in feature_set:\n",
    "            feature_set[f] = []\n",
    "        feature_set[f].append(dataset[i])\n",
    "#     for p in feature_set.values():\n",
    "#         print(p)\n",
    "#         print('\\n\\n')\n",
    "#         print(ent_calc(p))\n",
    "\n",
    "    ent = sum([len(p)/length*ent_calc(p)for p in feature_set.values()])\n",
    "    return ent\n",
    "\n",
    "def info_gain(ent_calc, ent_resid):\n",
    "    return ent_calc-ent_resid\n",
    "\n",
    "def info_gain_train(dataset):\n",
    "    columns = len(dataset[0])-1\n",
    "    ent = ent_calc(dataset)\n",
    "    best_feature = []\n",
    "    for i in range(columns):\n",
    "        cond_ent = ent_resid(dataset, axis=i)\n",
    "        gain = info_gain(ent, cond_ent)\n",
    "        best_feature.append((labels[i], gain))\n",
    "    print(best_feature)\n",
    "    best_  = max(best_feature, key = lambda x: x[-1])\n",
    "    return best_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99750254636911528"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_calc(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88937738110374998"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_resid(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('色泽', 0.10812516526536531), ('根底', 0.23887919623736464), ('敲声', 0.28192625011143702), ('纹理', 0.42976816669833717), ('脐部', 0.3589876656471539), ('触感', 0.0060464891765655837)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('纹理', 0.42976816669833717)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_gain_train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name \n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {'label':self.label, 'feature':self.feature, 'tree':self.tree}\n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "    \n",
    "    def predict(self, features):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "    \n",
    "# 计算熵\n",
    "    def ent_calc(self,dataset):\n",
    "        length = len(dataset)\n",
    "        label_count = {}\n",
    "        for i in range(length):\n",
    "            label = dataset[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        ent = -sum([pk/length*np.log2(pk/length) for pk in label_count.values()])\n",
    "        return ent\n",
    "\n",
    "# 计算经验熵\n",
    "    def ent_resid(self,dataset, axis=0):\n",
    "        length = len(dataset)\n",
    "        feature_set =  {}\n",
    "        for i in range(length):\n",
    "            f = dataset[i][axis]\n",
    "            if f not in feature_set:\n",
    "                feature_set[f] = []\n",
    "            feature_set[f].append(dataset[i])\n",
    "        ent = sum([len(p)/length*ent_calc(p)for p in feature_set.values()])\n",
    "        return ent\n",
    "\n",
    "# 信息增益\n",
    "    def info_gain(self, ent_calc, ent_resid):\n",
    "        return ent_calc-ent_resid\n",
    "\n",
    "# \n",
    "    def info_gain_train(self, dataset):\n",
    "        columns = len(dataset[0])-1\n",
    "        ent = ent_calc(dataset)\n",
    "        best_feature = []\n",
    "        for i in range(columns):\n",
    "            cond_ent = ent_resid(dataset, axis=i)\n",
    "            gain = info_gain(ent, cond_ent)\n",
    "            best_feature.append((i, gain))\n",
    "        print(best_feature)\n",
    "        best_  = max(best_feature, key = lambda x: x[-1])\n",
    "        return best_\n",
    "# \n",
    "    def train(self, train_data):\n",
    "        _, y_train, features = train_data.iloc[:, :-1], train_data.iloc[:, -1], train_data.columns[:-1]\n",
    "        \n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root=True, label=y_train.iloc[0])\n",
    "        \n",
    "        if len(features) == 0:\n",
    "            return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "        # 计算最大信息增益，\n",
    "        max_feature, max_info_gain = self.info_gain_train(train_data.as_matrix())\n",
    "        max_feature_name = features[max_feature]\n",
    "        \n",
    "        # 4.Ag的信息增益小于阈值\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "        \n",
    "        # 5. 构建Ag子集\n",
    "        node_tree = Node(root=False, feature_name=max_feature_name, feature=max_feature)\n",
    "        \n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "        for f in feature_list:\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop([max_feature_name], axis=1)\n",
    "            \n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "        return node_tree\n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        return self._tree.predict(x_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()\n",
    "datasets = pd.DataFrame(datasets, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.10812516526536531), (1, 0.23887919623736464), (2, 0.28192625011143702), (3, 0.42976816669833717), (4, 0.3589876656471539), (5, 0.0060464891765655837)]\n",
      "[(0, 0.0760098536627829), (1, 0.46956521111470695), (2, 0.34745764364708642), (3, 0.46956521111470695), (4, 0.46956521111470695)]\n",
      "[(0, 0.25162916738782293), (1, 0.0), (2, 0.0), (3, 0.25162916738782293)]\n",
      "[(0, 0.0), (1, 0.0), (2, 1.0)]\n",
      "[(0, 0.32192809488736229), (1, 0.072905595320056027), (2, 0.32192809488736229), (3, 0.17095059445466865), (4, 0.72192809488736231)]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree()\n",
    "tree = dt.fit(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Node object at 0x000001C078DECB00>\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义节点类 二叉树\n",
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {'label:': self.label, 'feature': self.feature, 'tree': self.tree}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "\n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "\n",
    "    def predict(self, features):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features)\n",
    "    \n",
    "class DTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "\n",
    "    # 熵\n",
    "    @staticmethod\n",
    "    def calc_ent(datasets):\n",
    "        data_length = len(datasets)\n",
    "        label_count = {}\n",
    "        for i in range(data_length):\n",
    "            label = datasets[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        ent = -sum([(p/data_length)*log(p/data_length, 2) for p in label_count.values()])\n",
    "        return ent\n",
    "\n",
    "    # 经验条件熵\n",
    "    def cond_ent(self, datasets, axis=0):\n",
    "        data_length = len(datasets)\n",
    "        feature_sets = {}\n",
    "        for i in range(data_length):\n",
    "            feature = datasets[i][axis]\n",
    "            if feature not in feature_sets:\n",
    "                feature_sets[feature] = []\n",
    "            feature_sets[feature].append(datasets[i])\n",
    "        cond_ent = sum([(len(p)/data_length)*self.calc_ent(p) for p in feature_sets.values()])\n",
    "        return cond_ent\n",
    "\n",
    "    # 信息增益\n",
    "    @staticmethod\n",
    "    def info_gain(ent, cond_ent):\n",
    "        return ent - cond_ent\n",
    "\n",
    "    def info_gain_train(self, datasets):\n",
    "        count = len(datasets[0]) - 1\n",
    "        ent = self.calc_ent(datasets)\n",
    "        best_feature = []\n",
    "        for c in range(count):\n",
    "            c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "        # 比较大小\n",
    "        best_ = max(best_feature, key=lambda x: x[-1])\n",
    "        return best_\n",
    "\n",
    "    def train(self, train_data):\n",
    "        \"\"\"\n",
    "        input:数据集D(DataFrame格式)，特征集A，阈值eta\n",
    "        output:决策树T\n",
    "        \"\"\"\n",
    "        _, y_train, features = train_data.iloc[:, :-1], train_data.iloc[:, -1], train_data.columns[:-1]\n",
    "        # 1,若D中实例属于同一类Ck，则T为单节点树，并将类Ck作为结点的类标记，返回T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root=True,\n",
    "                        label=y_train.iloc[0])\n",
    "\n",
    "        # 2, 若A为空，则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T\n",
    "        if len(features) == 0:\n",
    "            return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "\n",
    "        # 3,计算最大信息增益 同5.1,Ag为信息增益最大的特征\n",
    "        max_feature, max_info_gain = self.info_gain_train(np.array(train_data))\n",
    "        max_feature_name = features[max_feature]\n",
    "\n",
    "        # 4,Ag的信息增益小于阈值eta,则置T为单节点树，并将D中是实例数最大的类Ck作为该节点的类标记，返回T\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "\n",
    "        # 5,构建Ag子集\n",
    "        node_tree = Node(root=False, feature_name=max_feature_name, feature=max_feature)\n",
    "\n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "        for f in feature_list:\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop([max_feature_name], axis=1)\n",
    "\n",
    "            # 6, 递归生成树\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "\n",
    "        # pprint.pprint(node_tree.tree)\n",
    "        return node_tree\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self._tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_():\n",
    "    dataset = [        ['青绿','蜷缩', '浊响', '清晰', '凹陷', '硬滑', '1'],\n",
    "                       ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '1'],\n",
    "                       ['乌黑',' 蜷缩',' 浊响',' 清晰',' 凹陷', '硬滑', '1'],\n",
    "                       ['青绿',' 蜷缩',' 沉闷',' 清晰',' 凹陷', '硬滑', '1'],\n",
    "                       ['浅白',' 蜷缩',' 浊响',' 清晰',' 凹陷', '硬滑', '1'],\n",
    "                       ['青绿',' 稍蜷',' 浊响',' 清晰',' 稍凹', '软粘', '1'],\n",
    "                       ['乌黑',' 稍蜷',' 浊响',' 稍糊',' 稍凹', '软粘', '1'], \n",
    "                       ['乌黑',' 稍蜷',' 浊响',' 清晰',' 稍凹', '硬滑', '1'],\n",
    "                       ['乌黑',' 稍蜷',' 沉闷',' 稍糊',' 稍凹', '硬滑', '0'],\n",
    "                       ['青绿',' 硬挺',' 清脆',' 清晰',' 平坦', '软粘', '0'],\n",
    "                       ['浅白',' 硬挺',' 清脆',' 模糊',' 平坦', '硬滑', '0'], \n",
    "                       ['浅白',' 蜷缩',' 浊响',' 模糊',' 平坦', '软粘', '0'],\n",
    "                       ['青绿',' 稍蜷',' 浊响',' 稍糊',' 凹陷', '硬滑', '0'],\n",
    "                       ['浅白',' 稍蜷',' 沉闷',' 稍糊',' 凹陷', '硬滑', '0'],\n",
    "                       ['乌黑',' 稍蜷',' 浊响',' 清晰',' 稍凹', '软粘', '0'],\n",
    "                       ['浅白',' 蜷缩',' 浊响',' 模糊',' 平坦', '硬滑', '0'],\n",
    "                       ['青绿',' 蜷缩',' 沉闷',' 稍糊',' 稍凹', '硬滑', '0']\n",
    "                      ]\n",
    "  \n",
    "    labels = ['色泽', '根底', '敲声', '纹理', '脐部', '触感', '好瓜']\n",
    "    return pd.DataFrame(dataset, columns=labels)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets, labels = create_data()\n",
    "data_df = pd.DataFrame(datasets, columns=labels)\n",
    "dt = DTree()\n",
    "tree = dt.fit(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label:': None, 'feature': 3, 'tree': {' 清晰': {'label:': None, 'feature': 1, 'tree': {' 蜷缩': {'label:': '好', 'feature': None, 'tree': {}}, ' 稍蜷': {'label:': None, 'feature': 0, 'tree': {'乌黑': {'label:': None, 'feature': 2, 'tree': {'硬滑': {'label:': '好', 'feature': None, 'tree': {}}, '软粘': {'label:': '坏', 'feature': None, 'tree': {}}}}, '青绿': {'label:': '好', 'feature': None, 'tree': {}}}}, ' 硬挺': {'label:': '坏', 'feature': None, 'tree': {}}}}, ' 稍糊': {'label:': None, 'feature': 4, 'tree': {'硬滑': {'label:': '坏', 'feature': None, 'tree': {}}, '软粘': {'label:': '好', 'feature': None, 'tree': {}}}}, ' 模糊': {'label:': '坏', 'feature': None, 'tree': {}}, '清晰': {'label:': '好', 'feature': None, 'tree': {}}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
